# -*- coding: utf-8 -*-
"""dicoding_klasifikasiGambar_akhdanArifuddin.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1y6ClA0TZ4U-3C4Kxye8fBXUF4gif0zty
"""

!pip install wget
!pip install keras_preprocessing

import wget
import os
import zipfile
import keras_preprocessing
import tensorflow as tf
import pandas as pd
import matplotlib.pyplot as plt
import numpy as np
from tensorflow import keras
from keras_preprocessing import image
from keras_preprocessing.image import ImageDataGenerator
from google.colab import files

!wget --help

!wget --no-check-certificate https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip



"""Tahapan awal adalah melakukan unzipping dari file yang sudah berhasil di download sebelumnya, dimana disini saya menggunakan modul zipfile yang sudah dijalankan sebelumnya"""

local_zip = '/content/rockpaperscissors.zip'
zip_ref = zipfile.ZipFile(local_zip, 'r')
zip_ref.extractall('/content/')
zip_ref.close()

"""Selanjutnya adalah melihat isi dari file zip yang sebelumnya sudah di unzip, karena tentu saja untuk bisa melakukan proses kita harus mengetahui apa saja yang terdapat di dalam file tersebut"""

from zipfile import ZipFile
zip_f = ZipFile("/content/rockpaperscissors.zip")
for f in zip_f.namelist():
    zinfo = zip_f.getinfo(f)
    if(zinfo.is_dir()):
        print(f)

"""Pada tahapan ini saya melakukan pendefinisian dari gambar-gambar yang tersedia dalam file sebelumnya dimana gambar tersebut merupakan gambar tangan yang berbentuk gunting, batu, dan kertas"""

fold_scissors = os.path.join('/content/rockpaperscissors/scissors')
fold_rock= os.path.join('/content/rockpaperscissors/rock')
fold_paper = os.path.join('/content/rockpaperscissors/paper')

file_scissors = os.listdir(fold_scissors)
file_rock = os.listdir(fold_rock)
file_paper = os.listdir(fold_paper)

"""Selanjutnya melakukan proses augmentasi gambar pada setiap sampel di dataset"""

base_dir = "/content/rockpaperscissors/rps-cv-images/"

train_datagen = ImageDataGenerator(
      rescale = 1./255,
      validation_split=0.4,
	    rotation_range=40,
      width_shift_range=0.2,
      height_shift_range=0.2,
      shear_range=0.2,
      zoom_range=0.2,
      horizontal_flip=True,
      fill_mode='nearest',

      )

"""Disini menggunakan fungsi flow untuk mempersiapkan data train dan test yang nantinya akan di proses lebih lanjut"""

train_generator = train_datagen.flow_from_directory(
	base_dir,
	target_size=(150,150),
	class_mode='categorical',
  shuffle=True,
  subset='training'
  )

validation_generator = train_datagen.flow_from_directory(
	base_dir,
	target_size=(150,150),
	class_mode='categorical',
  shuffle=True,
  subset='validation'
  )

"""Disini saya menggunakan CNN untuk melakukan proses konvolusi dan max pooling"""

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),
    tf.keras.layers.MaxPooling2D(2,2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation='relu'),
    tf.keras.layers.Dense(3, activation='softmax')
])
model.summary()

"""Setelah itu selanjutnya melakukan proses compile yang mana disini saya menggunakan model root mean square propagation dan categorical crossentropy karena memang pada kasus ini seharusnya menggunakan categorical bukan binary"""

model.compile(loss = 'categorical_crossentropy',
              optimizer='rmsprop',
              metrics=['accuracy'])

"""Tahapan selanjutnya adalah melakukan proses fitting untuk melatih model pada data masukan dan label yang bersesuaian berdasarkan data training pada jaringan Neural Network yang telah saya buat sebelumnya"""

history=model.fit(
    train_generator,
    steps_per_epoch=15,
    epochs=50,
    validation_data=validation_generator,
    validation_steps=4,
    verbose=2
    )

"""Karena sudah melakukan proses training, maka saya disini  mencoba untuk menampilkan visualisasi dari seluruh hasil akurasi yang didapatkan pada setiap epoch yang terjadi dengan seperti ini nantinya dapat lebih mudah untuk melakukan analisa terkait hasil yang sudah didapatkan"""

model_history = pd.DataFrame(history.history)
model_history['epoch'] = history.epoch

fig, ax = plt.subplots(1, figsize=(8,6))
num_epochs = model_history.shape[0]

ax.plot(np.arange(0, num_epochs), model_history["accuracy"],
        label="Training Accuracy")
ax.plot(np.arange(0, num_epochs), model_history["val_accuracy"],
        label="Validation Accuracy")
ax.plot(np.arange(0, num_epochs), model_history["loss"],
        label="Training Loss")
ax.plot(np.arange(0, num_epochs), model_history["val_loss"],
        label="Validation Loss")
ax.legend()

plt.tight_layout()
plt.show()

"""Adapun tahapan terakhir adalah melakukan uji coba dari semua proses yang sudah saya lakukan sebelumnya, di tahapan ini saya memasukkan foto yang sudah tersimpan pada device saya untuk diserahkan kepada sistem yang mana nantinya sistem akan mengidentifikasi jenis tangan dari foto yang saya masukkan"""

uploaded = files.upload()

for fn in uploaded.keys():

  # predicting images
  path = fn
  img = image.load_img(path, target_size=(150,150))

  imgplot = plt.imshow(img)
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  images = np.vstack([x])

  classes = model.predict(images, batch_size=10)
  print(fn)
  if classes[0][0]==1:
    print('Gambar yang anda masukkan adalah tangan berbentuk kertas')
  elif classes[0][1]==1:
    print('Gambar yang anda masukkan adalah tangan berbentuk batu')
  elif classes[0][2]==1:
    print('Gambar yang anda masukkan adalah tangan berbentuk gunting')
  else:
    print('Maaf, gambar yang anda masukkan tidak dapat kami indentifikasi')